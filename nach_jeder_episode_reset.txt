import gym
import numpy as np
import pybullet as p
import pybullet_data
from gym import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback
import matplotlib.pyplot as plt
import time

class StackBlocksEnv(gym.Env):
    """
    Gym environment for stacking 10 blocks using a Franka Panda arm in PyBullet.
    Rewards agent for approaching any block (shaping) and for stacking all 10 blocks (base).
    Each episode starts fresh, preserving neither arm nor blocks between episodes.
    """
    metadata = {'render.modes': ['human']}

    def __init__(self, gui=True, max_steps=1000):
        super(StackBlocksEnv, self).__init__()
        self.gui = gui
        self.max_steps = max_steps
        self.num_blocks = 10
        self.block_size = 0.04
        # PyBullet setup
        if self.gui:
            p.connect(p.GUI)
        else:
            p.connect(p.DIRECT)
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        p.setGravity(0, 0, -9.81)
        # Load static scene
        p.loadURDF("plane.urdf")
        p.loadURDF("table/table.urdf", [0.5, 0, -0.65], useFixedBase=True)
        # Draw red stacking area
        for start, end in [([0.2, -0.2, 0], [0.2, 0.2, 0]),
                           ([0.2, 0.2, 0], [0.8, 0.2, 0]),
                           ([0.8, 0.2, 0], [0.8, -0.2, 0]),
                           ([0.8, -0.2, 0], [0.2, -0.2, 0])]:
            p.addUserDebugLine(start, end, [1, 0, 0], 2)
        # Load robot
        self.robot = p.loadURDF("franka_panda/panda.urdf", [0, 0, 0], useFixedBase=True)
        self.arm_joints = list(range(7))
        self.gripper_joints = [9, 11]
        self.ee_link = 11
        # Spawn blocks
        self.block_ids = []
        self._spawn_blocks()
        # Define spaces
        self.action_space = spaces.Box(low=-1, high=1, shape=(9,), dtype=np.float32)
        obs_dim = 7 + self.num_blocks * 3
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)
        # Initialize episode
        self.reset()

    def _spawn_blocks(self):
        # Remove existing if any
        for bid in self.block_ids:
            try: p.removeBody(bid)
            except: pass
        self.block_ids = []
        for _ in range(self.num_blocks):
            x = np.random.uniform(0.2, 0.8)
            y = np.random.uniform(-0.2, 0.2)
            z = self.block_size / 2
            bid = p.loadURDF("cube.urdf", [x, y, z], globalScaling=self.block_size/0.5)
            self.block_ids.append(bid)

    def reset(self):
        # Full reset each episode
        p.resetSimulation()
        p.setGravity(0, 0, -9.81)
        # Reload scene and blocks
        p.loadURDF("plane.urdf")
        p.loadURDF("table/table.urdf", [0.5, 0, -0.65], useFixedBase=True)
        for start, end in [([0.2, -0.2, 0], [0.2, 0.2, 0]),
                           ([0.2, 0.2, 0], [0.8, 0.2, 0]),
                           ([0.8, 0.2, 0], [0.8, -0.2, 0]),
                           ([0.8, -0.2, 0], [0.2, -0.2, 0])]:
            p.addUserDebugLine(start, end, [1, 0, 0], 2)
        self.robot = p.loadURDF("franka_panda/panda.urdf", [0, 0, 0], useFixedBase=True)
        self._spawn_blocks()
        self.step_count = 0
        return self._get_obs()

    def step(self, action):
        # Apply joint actions
        for idx, j in enumerate(self.arm_joints):
            curr = p.getJointState(self.robot, j)[0]
            target = curr + action[idx] * 0.05
            p.setJointMotorControl2(self.robot, j, p.POSITION_CONTROL, target)
        # Gripper control
        grip = action[7]
        p.setJointMotorControl2(self.robot, self.gripper_joints[0], p.POSITION_CONTROL, grip)
        p.setJointMotorControl2(self.robot, self.gripper_joints[1], p.POSITION_CONTROL, grip)
        # Step simulation
        p.stepSimulation()
        if self.gui:
            time.sleep(1./240.)
        self.step_count += 1
        # Observation
        obs = self._get_obs()
        # Shaping: approach any block
        shaping = 0.0
        ee_pos = p.getLinkState(self.robot, self.ee_link)[0]
        for bid in self.block_ids:
            bp, _ = p.getBasePositionAndOrientation(bid)
            d = np.linalg.norm(np.array(ee_pos) - np.array(bp))
            shaping += max(0, 1 - d/0.5)
        # Base: count properly stacked blocks
        base = self._compute_base_reward()
        reward = shaping + base
        # Done if timeout or full tower
        done = (self.step_count >= self.max_steps) or (base >= self.num_blocks)
        return obs, reward, done, {}

    def _get_obs(self):
        joints = [p.getJointState(self.robot, j)[0] for j in self.arm_joints]
        blocks = []
        for bid in self.block_ids:
            pos, _ = p.getBasePositionAndOrientation(bid)
            blocks.extend(pos)
        return np.array(joints + blocks, dtype=np.float32)

    def _compute_base_reward(self):
        count = 0
        tol = 0.02
        cx, cy = 0.5, 0.0
        for i, bid in enumerate(self.block_ids):
            pos, _ = p.getBasePositionAndOrientation(bid)
            target_z = (i + 0.5) * self.block_size
            if abs(pos[2] - target_z) < tol and np.hypot(pos[0] - cx, pos[1] - cy) < tol:
                count += 1
            else:
                break
        return count

    def render(self, mode='human'):
        pass

    def close(self):
        p.disconnect()

class RewardPlotCallback(BaseCallback):
    def __init__(self, verbose=0):
        super().__init__(verbose)
        self.episode_rewards = []

    def _on_step(self) -> bool:
        if self.locals.get('dones'):
            self.episode_rewards.append(self.locals['rewards'])
        return True

    def plot(self):
        plt.figure()
        plt.plot(self.episode_rewards)
        plt.xlabel('Episode')
        plt.ylabel('Reward')
        plt.title('Learning Curve')
        plt.show()

if __name__ == '__main__':
    env = StackBlocksEnv(gui=True, max_steps=1000)
    model = PPO('MlpPolicy', env, verbose=1, learning_rate=1e-3)
    callback = RewardPlotCallback()
    model.learn(total_timesteps=1_000_000, callback=callback)
    model.save('stacking_model_shaping.zip')
    callback.plot()
